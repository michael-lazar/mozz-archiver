#!/usr/bin/env python3
"""
Do some post-processing on a collection of warc files from a single crawl.

Combine small files that were generated by pausing/resuming the crawl midway
through. Fixup any data inconsistencies.
"""
import re
import argparse
import pathlib

from warcio.archiveiterator import ArchiveIterator
from warcio.warcwriter import WARCWriter


class ArchiveWriter:

    def __init__(self, directory):
        self.directory = directory
        self.writer = None
        self.serial = 0
        self.max_filesize = 1_000_000_000  # 1 GB
        self.prefix = "gemini_oct2020"
        self.crawlhost = "mozz"
        self.warcinfo = {
            "hostname": "mozz.us",
            "ip": "104.248.235.140",
            "http-header-user-agent": "archiver-mozz",
            "robots": "classic",
            "operator": "Michael Lazar (michael@mozz.us)",
            "software": "mozz-archiver/1.1.0 (https://github.com/michael-lazar/mozz-archiver)",
            "isPartOf": "gemini-crawl-oct2020",
            "description": "Geminispace crawl for historical archive",
            "format": "WARC file version 1.1",
            "conformsTo": "http://iipc.github.io/warc-specifications/specifications/warc-format/warc-1.1/"
        }

    def build_writer(self, record):
        timestamp = record.rec_headers['WARC-Date'].split('.')[0]
        timestamp = re.sub('[T:.-]', '', timestamp)
        filename = '{prefix}-{timestamp}-{serial}-{crawlhost}.warc.gz'.format(
            prefix=self.prefix,
            timestamp=timestamp,
            serial=str(self.serial).zfill(6),
            crawlhost=self.crawlhost
        )
        fp = (self.directory / filename).open('wb')
        print(f'Creating file {filename}')
        writer = WARCWriter(fp, warc_version="WARC/1.1")

        warcinfo = writer.create_warcinfo_record(filename, self.warcinfo)
        warcinfo.rec_headers.replace_header('WARC-Date', record.rec_headers['WARC-Date'])
        writer.write_record(warcinfo)
        return writer

    def write_record(self, record):
        if self.writer is None:
            self.writer = self.build_writer(record)

        self.writer.write_record(record)
        if self.writer.out.tell() > self.max_filesize:
            self.serial += 1
            self.writer = None


parser = argparse.ArgumentParser()
parser.add_argument('--in-dir', default=".")
parser.add_argument('--out-dir', default="./out")
args = parser.parse_args()

in_dir = pathlib.Path(args.in_dir).resolve()
assert in_dir.is_dir()

out_dir = pathlib.Path(args.out_dir).resolve()
out_dir.mkdir(exist_ok=True)
assert out_dir.is_dir()

writer = ArchiveWriter(out_dir)

files = sorted(in_dir.glob("*.warc.gz"))
for file in files:
    with file.open('rb') as fp:
        for record in ArchiveIterator(fp):
            if record.rec_type != "warcinfo":
                writer.write_record(record)
